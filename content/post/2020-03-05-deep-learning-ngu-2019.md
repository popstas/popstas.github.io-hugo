+++
title = "Конспекты курса Deep Learning на пальцах 2019"
date = "2020-03-05T14:20:00+06:00"
slug = "deep-learning-ngu-2019"
Tags = ["ML", "tensorflow", "pytorch"]
draft = true
+++

[Курс "Deep learning на пальцах - 2019" от sim0nsays](https://www.youtube.com/playlist?list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb)

<img src="" />
<!--more-->

## 3 урок
ReLu - дефолтный выбор функции активации.

## 4 урок
Adam - дефолтный выбор градиентного спуска.

Batch size - размер выборки данных для одного прохода, чтобы не перемножать весь датасет (обычно это невозможно).

## 5 урок
8:49 - сравнение процессора и GPU по TFlops

18:00 - последствия ошибок на train, validate, test

TensorBoard - визуальное отображение loss & accuracy.

Annealing - гиперпараметр про уменьшение learning rate с течением эпох. В PyTorch это `torch.optim.lr_scheduler`. Применяется при недообучении (underfitting).

27:55 - про переобучение. Лечится регуляризацией.

L2 regularization - самое простое.

Dropout - рандомное убирание частей данных во время или после тренировки. Обычно вставляют в конце сети.

Batch normalization - слой после весов, делает поток предсказуемого масштаба: среднее 0, std 1 (стандартное отклонение). Убирает выбросы в датасете. Чаще ставят после слоя активации (ReLu). Обычно ставят после каждого слоя весов.

Если собрать ансамбль моделей, предсказывать всеми и выдавать среднее, то результаты должны быть чуть лучше.

Learning rate можно подбирать либо линейно, потом смотреть лучший, либо пилой (больше-меньше), это даёт возможность скатившейся в локальный минимум точке выпрыгнуть оттуда и скатиться в более оптимальный минимум. Из разных минимумов можно собрать ансамбль.

1:17:27 - про инженерный подбор гиперпараметров.

ONNX - стандарт экспорта моделей.


## 6. Convolutional Neural Networks
14:47 - паттерны (или фильтры) свёртки для обработки изображений

31:15 - padding и stride. Padding - заполнение (обычно нулями) частей, которые выходят за пределы матрицы. Stride - шаг, с которым скачем по матрице.

35:25 - pooling layer - слой, меняющий разрешение по формуле Max pool (берёт максимум из объединяемых пикселей). При обратном проходе градиент отдаётся максимальному пикселю, остальным отдаёт ноль. Ставится после слоя активации.

Архитектура CNN с Max pooling хорошо работает со сдвигами изображений.

45:30 - рецептивное поле (receptive field) - то, какого размера поле в исходном изображении влияет на конкретный нейрон.

50:15 - примеры архитектур CNN.

LeNet'98 - сеть для распознавания цифр в почтовых индексах.

ImageNet - датасет из 1М картин, размечено 1000 классов.

AlexNet'12 - 15.4% ошибок, 16М параметров.

VGG'14 - 6.8% ошибок, 140М параметров.

ResNet'15 - 3.57% ошибок, решение проблемы тренировки сети с большим кол-вом слоёв (> 50). Чтобы один из слоёв не ломал все вычисления, стали передавать вход сразу на выход, а слой может только подправить, `f(x)+x`. Вход передаётся на выход через 2 слоя + ReLu.

1:07:55 - transfer learning, переобучение чужой сети. Если у нас всего 10-100 картинок, то замораживаются все слои сети, кроме последнего (не тренируются), в последнем меняем классы.

Если картинок около 1000, то можно заморозить не все слои, а часть, оставшиеся тренировать с разным learning rate, чем глубже, тем медленнее.

1:17:40 - аугментация - создание картинок из картинок. Например, можно отразить картинку и увеличить датасет в 2 раза. Потом можно делать смещения, изменения цвета, повороты, наклоны и т.д.
Аугментацию вставляют после выбора минибатча. Есть готовая либа [1]. Встроенные либы тоже есть. Эффект как у ансамбля моделей.


## 7. Segmentation и Object Detection (Владимир Игловиков)
Сегментация - это попиксельная классификация, когда на выходе получается картинка того же разрешения, но у каждого пикселя есть инфа, к какому классу он относится.

FCN (fully convolutional network) - сеть без dense слоёв, только из convolution слоёв.

Dense слои - fully connected слои.

U-Net - сеть, условно состоящая из 2 частей: encoder (распознаёт картинку, уменьшая разрешение) и decoder (разворачивает распознанную картинку в первоначальное разрешение).


42:25 - FPN (feature pyramid network). Решает проблему масштаба. Делается несколько параллельных слоёв, которые работают с разными размерами картинок.

44:50 - U-Net + FPN. Разные слои (уровни пирамиды) работают с картинками разного разрешения, потом верхние слои с большим разрешением подаются на вход нижнего слоя и на вход следующего слоя.

49:55 - Segmentation loss function. Тут ничего не понял...

56:00 - вторая часть.

Детекция - определение габаритов объектов: координаты, класс, аттрибуты.

Делятся на One-shot и Two-shot, вторые точнее, но дольше.

One-shot детекторы: YOLO (You only look once) (делит картинку на квадраты, боксы рисует по контурам квадратов, менее точно, но быстрее).

One-shot detector + FPN = SSD.

Как я понял, из two-shot надо брать Faster-RCNN.


## 8. Metric Learning, Autoencoders, GANs

Embedding - внутреннее представление картинки нейросетью перед классификацией (на предпоследнем слое). Набор внеторов, отражающих все знания сети о картинке.

По векторам можно сравнивать картинки и находить похожие по заданному признаку, это может быть как поза любого человека, так и один и тот же человек в разных позах.

Тренируется такая модель через triplet loss. Каждый элемент в батче - 3 фото, 2 похожих, 3-я непохожая. Нужно найти такой loss, чтобы вектора похожих были ближе друг к другу, чем непохожая.

29:30 - Unsupervised learning (обучение без учителя) - обучение на неразмеченных данных.

Вместо предсказывания алгоритм находит общее:

- выявление схожих характеристик (clustering)
- выявление аномалий (outlier detection)
- выучить фичу, которая пригодится в другой модели (learning features)
- создание нового (generation)

Чтобы обучить сеть созданию, нужно на выходе генерировать такую же картинку, как на входе. Надо построить её так, чтобы в середине сети было недостаточно ёмкости, чтобы сохранить всю информацию о пикселях. Для этого сети нужно будет понять высокоуровневые параметры картинки. Сеть делится на encoder и decoder (который делает upsampling).

Автоэнкодеры быстро приходят к overfitting. Чтобы это обойти, прибумали variational autoencoder (VAE). Энкодер вместо предсказания пикселя выдаёт среднее и сигму, дисперсию (грубо говоря, центр и радиус). А декодеру мы будем передавать случайную точку из области этого круга. Чтобы шарики не схлопнулись в точку, добавляют дополнительный loss, который заставляет сеть делать сигму как можно больше.

Сеть можно научить определённому вектору, например, наличию улыбки, наличию очков. Когда вектор получен, мы можем добавлять или вычитать его в других картинках.

1:00:00 - Generative adversarial networks (GANs) или генеративно-состязательные сети. Состоят из 2 сетей. Геренатор должен из точки (случайный шум) дать картинку. Дискриминатор видит картинки генератора и картинки из датасета, он должен определять, реальная картинка или сгенерированная. Цели у сетей противоположные. Генератор должен научиться делать такие картинки, которые дискриминатор не распознает. Генератор имеет доступ к весам дискриминатора, поэтому он смотрит изнутри, как картинку определили.

GAN zoo - сотни ГАНов [3].

Современные: StyleGAN'18


## 9. Введение в NLP, word2vec
NLP сложно из-за того, что естественный язык сильно зависит от контекста. "Он видел их семью своими глазами".

9:45 - NLP pipleline

`Вход` (текст, распознавание речи, OCR) -> `Морфология` (проверка текста, поиск по словам) -> `Синтаксис` (крутая проверка текста, парсинг) -> `Семантика` (положительное/отрицательное, sentiment analysis, машинный перевод) -> `Контекст` (связывание предложений).

Чем дальше по пайплайну, тем труднее составить список правил, чтобы формализовать обработку.

22:00 - чтобы выразить задачу для нейросети, нужно перевести данные из символьного представления в непрерывное, то есть векторизовать. Как и в 8 уроке, в autoencoders, слова со схожим смыслом должны при этом оказаться ближе друг к другу и разбиться по кластерам.

30:30 - word2vec - одно из первых успешных решений. Использует подход skip-gram: берёт соседние слова у каждого слова в датасете предложений, для каждого определяет вероятность использования соседних слов. Контекст вокруг слова - n-gram.

В архитектуре такой сети нет нелинейности (ReLu). Размеры матриц в слоях пропорциональны длине словаря. 

51:10 - Проблема с этим наступает на softmax, где система должна умножить каждое слово в словаре, а их могут быть миллионы. Чтобы это обойти, придумали negative sampling. При тренировке выбирают несколько случайных слов и выводят по ним бинарное предсказание вместо softmax.

1:08:00 - FastText от Facebook, умеет определять вектора для новых слов: раскладывает слово на n-граммы, каждое векторизует, для новых слов берёт среднее из них, стоит брать эту модель для начала.


## 10. Recurrent Neural Networks, Рекуррентные нейронные сети
У обычных сетей 1 вход и 1 выход. Бывают другие варианты: 

- 1 вход, много выходов
- много входов, 1 выход (sentiment analysis)
- переменные входы, переменные выходы (перевод текста)
- много входов, столько же выходов

Рекуррентная сеть умеет запоминать выход на слое и на следующем шаге передавать самой себе в будущее это значение на вход, вместе с инпутом. Внутри слоя вычисляется `h`: вход умножается на веса + предыдущий выход умножается на веса и берётся среднее (грубо говоря). На следующем шаге `h` переиспользуется.

15:20 - Пример: генерация текста. Модель принимает символы по одному (+ "символы" BOS, EOS, начало и конец), учим её предсказывать следующий символ. Размер вектора - кол-во символов в языке.

34:50 - Как тренируется RNN. Сеть "разматывается", как будто один слой на разных шагах - разные слои.

Есть проблема: любой сигнал, умножаясь за 100 шагов на одну и ту же матрицу, становится очень большим. tanh его убьёт либо в 0, либо в 1, ReLu вообще нельзя использовать, т.к. значения уходят в небеса. Решают через long short-term memory (LSTM), в отличие от Vanilla RNN. Вместо 1 входа `h` делается 2 входа. `c` меняется по минимуму, чтобы градиенты протекали через него без экспоненциального изменения. В `h` добавляется несколько гейтов. Все гейты получают на вход конкатенацию векторов из `h` и `x`. Forget gate выдаёт вектор, равный размерности `c`, который говорит, сколько в `c` следует забыть. Input gate говорит, что нужно добавить (через tanh). Cell update говорит, что нужно передать на выход `c`. Output gate говорит, как нужно изменить значение `c`, чтобы выдать `h`. Это похоже на ResNet из 6 урока, где данные передавались без изменений через несколько слоёв.

59:10 - Bidirectional RNN

1:04:35 - Пример разбора частей речи (part of speech tagging) с зависимостью от контекста. Решение: many to many, Bidirectional LSTM с дополнением (CRF models).

1:05:50 - Нахождение именованных сущностей (named entity recognition, NER). Решение: many to many, Bidirectional LSTM CNN.

1:06:50 - Анализ тональности (sentiment analysis). Решение: many to one, LSTM.

1:07:15 - Машинный перевод (machine translation). Решение: many to many, LSTM.

1:08:35 - Использование в PyTorch.

1:12:05 - Разбор частей речи подробнее.


## 11. Аудио и распознавание речи (Юрий Бабуров)







## Ссылки

[1] - https://github.com/albumentations-team/albumentations
[2] - https://supervise.ly/
[3] - https://github.com/hindupuravinash/the-gan-zoo